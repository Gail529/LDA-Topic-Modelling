{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1SuUru3rXFQYcwpl0muBY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gail529/LDA-Topic-Modelling/blob/master/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXddWThlYEDy",
        "outputId": "248a7ac1-68fc-42f9-d1ea-c4b06cac4550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#importng the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gensim \n",
        "from gensim import corpora\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QHcrkNraFEh"
      },
      "source": [
        "corpus=pd.read_csv('/content/rock_emotion_scores.csv')\n",
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEgPXAeWalCs",
        "outputId": "70bece0d-c680-4ca6-8264-c57a8a651650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data=corpus[['song-title','lyrics']]\n",
        "data.head()#filtering off some features from our dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song-title</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yellow</td>\n",
              "      <td>look stars look shine everything yeah yellow c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Viva La Vida</td>\n",
              "      <td>used rule world seas would rise gave word morn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In My Place</td>\n",
              "      <td>place place lines could nt change lost oh yeah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>God Put A Smile Upon Your Face</td>\n",
              "      <td>go nobody knows got ta say way god give style ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Princess of China</td>\n",
              "      <td>oh upon time somebody ran somebody ran away sa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       song-title                                             lyrics\n",
              "0                          Yellow  look stars look shine everything yeah yellow c...\n",
              "1                    Viva La Vida  used rule world seas would rise gave word morn...\n",
              "2                     In My Place  place place lines could nt change lost oh yeah...\n",
              "3  God Put A Smile Upon Your Face  go nobody knows got ta say way god give style ...\n",
              "4               Princess of China  oh upon time somebody ran somebody ran away sa..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejHmzO5dcBDq"
      },
      "source": [
        "docs=data['lyrics']#column that will act as the documents\n",
        "tokenised_docs=[]#array that will store the tokenised documents \n",
        "from nltk.tokenize import word_tokenize\n",
        "for doc in docs:\n",
        "    word_tokens=word_tokenize(doc)#tokenizing the documents\n",
        "    tokenised_docs.append(word_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSpVspAWdvL6",
        "outputId": "e5545f89-94b6-4c50-f3f0-30326afb8639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenised_docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function list.count>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkUIl8i6a3-T"
      },
      "source": [
        "doc_dictionary=corpora.Dictionary(tokenised_docs)#mapping all the tokens in the documents into a unique id using gensim\n",
        "tokenids=doc_dictionary.token2id\n",
        "document_frequencies=doc_dictionary.dfs\n",
        "no_of_documents=doc_dictionary.num_docs\n",
        "print(tokenids)\n",
        "print(document_frequencies)\n",
        "print(no_of_documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9RVKgh2eIGb"
      },
      "source": [
        " doc_term_matrix = [doc_dictionary.doc2bow(doc) for doc in tokenised_docs] #using a dictionary to convert the documents into  a bag of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0zvLT78v3_6"
      },
      "source": [
        "Lda=gensim.models.ldamodel.LdaModel #\n",
        "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word =doc_dictionary, passes=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6PF80tO5CqK",
        "outputId": "5ac92211-1e2a-49c7-b25a-a0584ed91eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "ldamodel.print_topics(num_topics=3,num_words=10) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.027*\"I\" + 0.022*\"nt\" + 0.012*\"you\" + 0.012*\"my\" + 0.011*\"life\" + 0.010*\"oh\" + 0.010*\"boom\" + 0.009*\"make\" + 0.008*\"the\" + 0.008*\"to\"'),\n",
              " (1,\n",
              "  '0.040*\"oh\" + 0.026*\"I\" + 0.015*\"the\" + 0.015*\"nt\" + 0.014*\"you\" + 0.010*\"know\" + 0.010*\"it\" + 0.010*\"me\" + 0.010*\"get\" + 0.009*\"yeah\"'),\n",
              " (2,\n",
              "  '0.030*\"nt\" + 0.024*\"na\" + 0.020*\"love\" + 0.015*\"know\" + 0.013*\"like\" + 0.011*\"come\" + 0.011*\"oh\" + 0.010*\"go\" + 0.009*\"get\" + 0.008*\"cause\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}